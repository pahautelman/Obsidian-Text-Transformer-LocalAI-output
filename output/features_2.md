# Pipelines Support

## Key Concepts
- Pipelines Framework
- Upload Pipeline
- Function Calling
- Custom RAG
- Message Monitoring with Langfuse
- User Rate Limiting
- Real-Time LibreTranslate Translation
- Toxic Message Filtering
- LLM-Guard
- Conversation Turn Limits
- OpenAI Generation Stats
- Multi-Model Support

## Detailed Description

**Reference:** [https://github.com/open-webui/pipelines](https://github.com/open-webui/pipelines)

### Pipelines Framework
Seamlessly integrate and customize your Open WebUI experience with our modular plugin framework for enhanced customization and functionality. Our framework allows for the easy addition of custom logic and integration of Python libraries, from AI agents to home automation APIs.

### Upload Pipeline
Pipelines can be uploaded directly from the Admin Panel > Settings > Pipelines menu, streamlining the pipeline management process.

### Function Calling
Integrate Function Calling seamlessly through Pipelines to enhance your LLM interactions with advanced function calling capabilities.

### Custom RAG
Integrate a custom Retrieval Augmented Generation (RAG) pipeline seamlessly to enhance your LLM interactions with custom RAG logic.

### Message Monitoring with Langfuse
Monitor and analyze message interactions in real-time usage statistics via Langfuse pipeline.

### User Rate Limiting
Manage API usage efficiently by controlling the flow of requests sent to LLMs to prevent exceeding rate limits with Rate Limit pipeline.

### Real-Time LibreTranslate Translation
Integrate real-time translations into your LLM interactions using LibreTranslate pipeline, enabling cross-lingual communication. Please note that this pipeline requires further setup with LibreTranslate in a Docker container to work.

### Toxic Message Filtering
Our Detoxify pipeline automatically filters out toxic messages to maintain a clean and safe chat environment.

### LLM-Guard
Ensure secure LLM interactions with LLM-Guard pipeline, featuring a Prompt Injection Scanner that detects and mitigates crafty input manipulations targeting large language models. This protects your LLMs from data leakage and adds a layer of resistance against prompt injection attacks.

### Conversation Turn Limits
Improve interaction management by setting limits on conversation turns with Conversation Turn Limit pipeline.

### OpenAI Generation Stats
Our OpenAI pipeline provides detailed generation statistics for OpenAI models.

### Multi-Model Support
Our seamless integration with various AI models from various providers expands your possibilities with a wide range of language models to select from and interact with.

## Summary
The Pipelines Framework in Open WebUI offers extensive customization options, allowing users to integrate advanced functionalities like function calling, custom RAG pipelines, message monitoring, rate limiting, translation services, toxic message filtering, LLM security, conversation management, generation statistics, and multi-model support. These features enhance the versatility and efficiency of interactions within the platform.

# Tags
#pipelines #framework #functioncalling #RAG #monitoring #ratelimiting #translation #filtering #security #conversationmanagement #multimodel