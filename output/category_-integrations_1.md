# Run DeepSeek R1 Dynamic 1.58-bit with Llama.cpp

## Key Concepts
- Running DeepSeek-R1 model
- Quantized form (dynamic 1.58-bit)
- Personal machine compatibility
- UnslothAI contributions

## Detailed Description

**Reference:** [https://docs.openwebui.com/category/-integrations](https://docs.openwebui.com/category/-integrations)

### Overview
Thanks to the efforts of **UnslothAI**, it is now possible to run the DeepSeek-R1 model in its dynamic 1.58-bit quantized form on Llama.cpp.

### Model Details
- **Model Size:** The model has been compressed to just 131GB.
- **Hardware Requirements:**
  - No longer requires massive enterprise-class GPUs or servers.
  - Can be run on personal machines, though performance may vary based on consumer hardware.

## Summary

The DeepSeek-R1 671B parameter model can now be run in its dynamic 1.58-bit quantized form on Llama.cpp, thanks to UnslothAI's efforts. This allows for running the model on personal machines, albeit with slower performance on most consumer hardware.

# Tags
#DeepSeek #Llama.cpp #UnslothAI #model #quantization